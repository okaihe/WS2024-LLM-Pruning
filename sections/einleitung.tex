\section{Einleitung}

\subsection{Forschungsfragen}

Die vorliegende Projektarbeit setzt sich mit insgesamt vier Forschungsfragen
auseinander, die im Verlauf der Arbeit untersucht und beantwortet werden sollen.
Die erste Forschungsfrage beschäftigt sich mit dem aktuellen Stand der Forschung
im Bereich des Prunings von Large Language Models (LLMs). Dabei wird analysiert,
welche Methoden derzeit für das Pruning angewendet werden, welche Unterschiede
zwischen diesen bestehen und welche Vor- und Nachteile die jeweiligen Ansätze
mit sich bringen. Das Ziel dieser Untersuchung ist es, einen Überblick über den
aktuellen Stand der Forschung in diesem Bereich zu geben und die relevantesten
Methoden zu beschreiben.

Ein weiterer Aspekt dieser Arbeit ist die Analyse der verschiedenen Frameworks,
die Pruning-Methoden für LLMs unterstützen. Hierbei soll untersucht werden,
welche dieser Frameworks welche Methoden implementieren und wie sie in der
Praxis angewendet werden können. Basierend auf dieser Analyse wird eine
geeignete Auswahl getroffen und eines dieser Framework für die praktische
Umsetzung festgelegt.

Neben der theoretischen Auseinandersetzung mit dem Thema wird zudem ein eigener
praktischer Versuch durchgeführt. Hierzu wird ein geeignetes Basismodell
ausgewählt, das anschließend in verschiedenen Stufen geprunt wird. Die
Auswirkungen dieses Prunings werden untersucht und dokumentiert. Im Rahmen
dieser Analyse werden standardisierte Benchmarks erstellt, um die geprunten
Modelle zu bewerten. Dabei wird nicht nur die Performance hinsichtlich der
Ergebnisse in den Tests betrachtet, sondern auch der Einfluss des Prunings auf
den Speicherverbrauch und die benötigte Rechenzeit. Ziel ist es, Erkenntnisse
darüber zu gewinnen, wie sich das Pruning auf verschiedene Aspekte der Modelle
auswirkt.

Zusammenfassend ergeben sich daraus die folgenden Forschungsfragen:

\begin{enumerate}
	\item Wie ist der aktuelle Stand der Forschung im Bereich des
	      Prunings von Large Language Models, und welche Methoden werden derzeit
	      eingesetzt?
	\item Welche Frameworks bieten Unterstützung für das Pruning von
	      LLMs, und wie lassen sich diese in der Praxis anwenden?
	\item Welche
	      Auswirkungen hat das Pruning eines Modells auf dessen Leistungsfähigkeit in
	      Bezug auf standardisierte Benchmarks und Aufgaben?
	\item Inwiefern
	      beeinflusst das Pruning eines Modells dessen Speicherverbrauch sowie die
	      benötigte Rechenzeit?
\end{enumerate}
