\section{Ergebnisse}\label{ergebnisse}

Im folgenden Kapitel werden die Ergebnisse der Evaluierungen und Tests der
geprunten sowie teilweise anschließend trainierten Modelle vorgestellt. Dabei
liegt der Fokus insbesondere auf den ermittelten Perplexity-Werten sowie den
Ergebnissen der Tests mit dem \emph{lm-evaluation-harness}-Framework. Die
verschiedenen Pruning-Stufen und die dabei verwendeten Methoden werden einzeln
analysiert, bevor abschließend ein umfassender Gesamtüberblick über die
Ergebnisse gegeben wird.

\subsection{Evaluierung Basismodell}\label{evaluation-basemodel}

Um eine Vergleichsbasis zu schaffen, muss zunächst das Basismodell in allen
Tests evaluiert werden. Als Basismodell dient hierbei das
\emph{TinyLlama}-Modell (\emph{TinyLlama/TinyLlama-1.1B-Chat-v1.0}). Die
Darstellung der Ergebnisse orientiert sich an den vom \emph{LLM-Pruner} für
andere Modelle bereitgestellten Resultaten, um eine einheitliche
Vergleichbarkeit zu ermöglichen.

Die Spalte \emph{Average} gibt den Durchschnitt der getesteten \emph{Tasks}
wieder. Die Ergebnisse für \emph{WikiText2} und \emph{PTB} werden dabei nicht in
diese Berechnung einbezogen, da bei diesen Benchmarks ein niedrigerer Score eine
bessere Leistung des Modells widerspiegelt.

Die zusammengefassten Ergebnisse sind in der folgenden Tabelle
dargestellt:

\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{l l | c c | c c c c c | r}
			\toprule
			\textbf{Pruning Ratio}      & \textbf{Method} & \textbf{WikiText2} &
			\textbf{PTB}                & \textbf{BoolQ}  & \textbf{HellaSwag} &
			\textbf{WinoGrande}         & \textbf{ARC-c}  & \textbf{OBQA}      &
			\textbf{Average}                                                             \\
			\midrule
			\multirow{1}{*}{Pruned 0\%} & --              & 7.97               & 20.76 &
			61.31                       & 46.15           & 60.30              &
			30.12                       & 24.20           & 39,58                        \\
			\midrule
		\end{tabular}}
	\caption{Evaluierung des Basismodells}
	\label{tab:pruning}
\end{table}


Wie hier zu erkennen ist, weist das Basismodell bereits einen vergleichsweise
niedrigen Score von \emph{39,58} auf. Zum Vergleich: In den Ergebnissen des
\emph{LLM-Pruners} für das Modell \emph{Llama7B} ergibt sich ein
Durchschnittswert von \emph{68,59}. Allerdings wurden in diesen Tests noch
weitere \emph{Tasks} berücksichtigt, die in der vorliegenden Analyse nicht
enthalten sind.

Da sich diese Untersuchung jedoch auf die relative Verschlechterung im Vergleich
zum Basismodell konzentriert, stellt der niedrigere Ausgangswert hier kein
Problem dar.

\newpage

\subsection{Tatsächliche Anzahl geprunter Parameter}\label{param_count}

Anhand der Modellevaluierungen, die nach dem dem Pruning über das
Evaluierungsskript erstellt wurden, lässt sich schnell erkennen, dass die im
Befehl angegebene Menge an zu prunenden Parametern bzw. das definierte
Verhältnis nicht exakt so vom \emph{LLM-Pruner} umgesetzt wird.

Am Beispiel des \emph{30\%}-Prunings sieht dies wie folgt aus: Bei einer
angegebenen Pruning-Ratio von \emph{30\%} wäre zu erwarten, dass nach dem
Pruning noch \emph{70\%} der ursprünglichen Parameter des Basismodells erhalten
bleiben. Tatsächlich sind es in diesem Fall jedoch \emph{73,06\%}, also
\emph{3,06\%} mehr als ursprünglich vorgesehen.

Noch deutlicher wird diese Abweichung bei einer Pruning-Ratio von \emph{70\%}.
Hier sollten theoretisch nur noch \emph{30\%} der Parameter im Modell
verbleiben, tatsächlich sind es jedoch noch \emph{55,08\%}, was einer Differenz
von \emph{25,08\%} entspricht.

Diese Diskrepanz muss bei der Interpretation der nachfolgenden Ergebnisse
berücksichtigt werden, da die angegebenen Verhältnisse nicht mit den
tatsächlichen übereinstimmen.

\begin{table}[h]
	\centering
	\begin{tabular}{c | c c | c }
		\toprule
		\textbf{Specified ratio} & \textbf{\#Parameters before} & \textbf{\#Parameters after} & \textbf{Actual ratio} \\
		\midrule
		30\%                     & 1261.53 Mio                  & 921.65 Mio                  & 73.06\%               \\
		40\%                     & 1261.53 Mio                  & 873.22 Mio                  & 69.21\%               \\
		70\%                     & 1261.53 Mio                  & 694.83 Mio                  & 55,08\%               \\
		\midrule
	\end{tabular}
	\caption{Anzahl der vorhandenen Parameter nach dem Pruning}
	\label{tab:actualparameters}
\end{table}

\newpage

\subsection{Evaluierung Pruning zu 30\%}\label{evaluation-30}

In Tabelle \ref{tab:pruning30} sind die Ergebnisse der geprunten Modelle sowie
die des Basismodells dargestellt. Getestet wurden – wie in Kapitel
\ref{methodik} beschrieben – die \emph{Tasks} BoolQ, HellaSwag, WinoGrande,
Arc-Challenge und OpenBookQA. Zusätzlich wurde die \emph{Perplexity} anhand der
Datensätze WikiText2 und PTB ermittelt.

\vspace{1em}
\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{l l | c c | c c c c c | r}
			\toprule
			\toprule
			\textbf{Pruning Ratio}       & \textbf{Method} & \textbf{WikiText2} &
			\textbf{PTB}                 & \textbf{BoolQ}  & \textbf{HellaSwag} &
			\textbf{WinoGrande}          & \textbf{ARC-c}  & \textbf{OBQA}      & \textbf{Average}   \\
			\midrule

			\multirow{1}{*}{Pruned 0\%}  & --              & 7.97               & 20.76
			                             & 61.31           & 46.15              & 60.30            &
			30.12                        & 24.20           & 39.58                                   \\

			\midrule

			\multirow{4}{*}{Pruned 30\%} & Taylor          & 15.19              & 43.19
			                             & 55.50           & 37.90              & 54.22
			                             & 24.66           & 23.20              & 39.10              \\

			                             & L1              & 281.63             & 4992.16
			                             & 46.54           & 28.53              & 48.46
			                             & 21.33           & 14.00              & 31.77              \\


			                             & L2              & 42.19              & 167.51
			                             & 60.89           & 35.97              & 54.30
			                             & 22.95           & 18.40              & 38.50              \\


			                             & Random          & 40.89              & 166.21
			                             & 59.63           & 33.18              & 53.99
			                             & 20.99           & 18.00              & 37.17              \\
			\midrule
			Pruned 30\% (tuned)          & Taylor          & /                  & /
			                             & 45.75           & 39.29              & 56.67
			                             & 25.26           & 22.00              & 37.79              \\
			\bottomrule
			\bottomrule
		\end{tabular}}
	\caption{Evaluierungen bis 30\% Pruning}
	\label{tab:pruning30}
\end{table}

Es ist wichtig zu beachten, dass die tatsächliche Anzahl an Parametern im
Vergleich zum Basismodell nur um \emph{16,22\%} reduziert wurde – und nicht, wie
ursprünglich erwartet, um volle \emph{30\%}. Die Tests wurden unmittelbar nach
dem Pruning durchgeführt, ohne dass ein erneutes Fine-Tuning erfolgte.

Betrachtet man ausschließlich die Ergebnisse der \emph{Tasks} und deren
Durchschnittswerte, so schneiden die \emph{Taylor}- und \emph{L2}-Methoden am
besten ab, da ihre Werte am nächsten an denen des Basismodells liegen.
Allerdings zeigt sich bei der \emph{L2}-Methode eine deutlich höhere und damit
schlechtere \emph{Perplexity} in beiden Datensätzen im Vergleich zur
\emph{Taylor}-Methode. Hervorzuheben ist dennoch, dass sie in der
\emph{BoolQ}-Task um \emph{5,39} Prozentpunkte besser abgeschnitten hat als die
\emph{Taylor}-Methode.

Die \emph{Random}-Methode weist mit dessen Resultaten Ähnlichkeiten zu der
\emph{L2}-Methode auf und schneidet somit ebenfalls schlechter als
\emph{Taylor}-Methode ab. Hier sind somit keine weiteren Auffälligkeiten
Hervorzuheben.

Am schlechtesten hat die \emph{L1}-Methode abgeschnitten: Das daraus
resultierende Modell weist extrem schlechte \emph{Perplexity}-Werte auf, und
auch der Durchschnitt der \emph{Tasks} liegt im Vergleich zu den anderen
Methoden deutlich niedriger.

In der letzten Zeile der Tabelle sind zusätzlich die Ergebnisse des
nachtrainierten Taylor-Modells zu sehen. Leider konnten hier nicht ähnliche
Ergebnisse wie in der Dokumentation des \emph{LLM-Pruners} erzielt werden. Nach
einem dreistündigen Post-Training ist der Durchschnittswert von 39,85 auf 37,79
gesunken. Das Modell hat damit nach dem Post-Training schlechtere Ergebnisse
geliefert als davor. Allein in den Evaluierungsaufgaben \emph{HellaSwag} und
\emph{ARC-c} konnte eine leichte Steigerung erzielt werden.

\newpage

\subsection{Evaluierung Pruning zu 40\%}

In Tabelle \ref{tab:pruning40} sind die Inhalte der Tabelle
\ref{tab:pruning30} ergänzt um die Ergebnisse der Tests zu den Modellen, die mit
der Angabe \emph{40\%} geprunt wurden zu sehen. Es wurden erneut jeweils die
vier möglichen Methoden angewendet und getestet.

\vspace{1em}
\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{l l | c c | c c c c c | r}
			\toprule
			\toprule
			\textbf{Pruning Ratio}       & \textbf{Method} & \textbf{WikiText2} &
			\textbf{PTB}                 & \textbf{BoolQ}  & \textbf{HellaSwag} &
			\textbf{WinoGrande}          & \textbf{ARC-c}  & \textbf{OBQA}      & \textbf{Average} \\
			\midrule

			\multirow{1}{*}{Pruned 0\%}  & --              & 7.97               & 20.76
			                             & 61.31           & 46.15              & 60.30
			                             & 30.12           & 24.20              & 39,58            \\

			\midrule

			\multirow{4}{*}{Pruned 30\%} & Taylor          & 15.19              & 43.19
			                             & 55.50           & 37.90              & 54.22
			                             & 24.66           & 23.20              & 39.10            \\

			                             & L1              & 281.63             & 4992.16
			                             & 46.54           & 28.53              & 48.46
			                             & 21.33           & 14.00              & 31.77            \\


			                             & L2              & 42.19              & 167.51
			                             & 60.89           & 35.97              & 54.30
			                             & 22.95           & 18.40              & 38.50            \\


			                             & Random          & 40.89              & 166.21
			                             & 59.63           & 33.18              & 53.99
			                             & 20.99           & 18.00              & 37.17            \\
			\midrule
			Pruned 30\% (tuned)          & Taylor          & /                  & /
			                             & 45.75           & 39.29              & 56.67
			                             & 25.26           & 22.00              & 37.79            \\
			\midrule

			\multirow{4}{*}{Pruned 40\%} & Taylor          & 18.43              & 53.33
			                             & 59.39           & 34.84              & 52.88
			                             & 23.55           & 18.80              & 37.89            \\

			                             & L1              & 441.35             & 14000.87
			                             & 48.99           & 28.13              & 49.96
			                             & 21.42           & 14.80              & 32.66            \\


			                             & L2              & 86.23              & 229.87
			                             & 60.83           & 34.18              & 51.62
			                             & 21.08           & 19.60              & 37.59            \\


			                             & Random          & 86.91              & 364.46
			                             & 57.89           & 30.82              & 52.33
			                             & 20.56           & 17.00              & 35.72            \\
			\bottomrule
			\bottomrule
		\end{tabular}}
	\caption{Evaluierungen bis 40\% Pruning}
	\label{tab:pruning40}
\end{table}

Auch hier zeigt sich, dass die Taylor-Methode die vielversprechendsten Ergebnisse erzielt.

\newpage

\subsection{Evaluierung Pruning zu 70\%}

\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{l l | c c | c c c c c | r}
			\toprule
			\toprule
			\textbf{Pruning Ratio}       & \textbf{Method} & \textbf{WikiText2} &
			\textbf{PTB}                 & \textbf{BoolQ}  & \textbf{HellaSwag} &
			\textbf{WinoGrande}          & \textbf{ARC-c}  & \textbf{OBQA}      & \textbf{Average} \\
			\midrule
			\multirow{1}{*}{Pruned 0\%}  & --              & 7.97               & 20.76
			                             & 61.31           & 46.15              & 60.30
			                             & 30.12           & 24.20              & 39,58            \\

			\midrule
			\multirow{4}{*}{Pruned 30\%} & Taylor          & 15.19              & 43.19
			                             & 55.50           & 37.90              & 54.22
			                             & 24.66           & 23.20              & 39.10            \\

			                             & L1              & 281.63             & 4992.16
			                             & 46.54           & 28.53              & 48.46
			                             & 21.33           & 14.00              & 31.77            \\

			                             & L2              & 42.19              & 167.51
			                             & 60.89           & 35.97              & 54.30
			                             & 22.95           & 18.40              & 38.50            \\

			                             & Random          & 40.89              & 166.21
			                             & 59.63           & 33.18              & 53.99
			                             & 20.99           & 18.00              & 37.17            \\

			\midrule
			Pruned 30\% (tuned)          & Taylor          & /                  & /
			                             & 45.75           & 39.29              & 56.67
			                             & 25.26           & 22.00              & 37.79            \\

			\midrule
			\multirow{4}{*}{Pruned 40\%} & Taylor          & 18.43              & 53.33
			                             & 59.39           & 34.84              & 52.88
			                             & 23.55           & 18.80              & 37.89            \\

			                             & L1              & 441.35             & 14000.87
			                             & 48.99           & 28.13              & 49.96
			                             & 21.42           & 14.80              & 32.66            \\


			                             & L2              & 86.23              & 229.87
			                             & 60.83           & 34.18              & 51.62
			                             & 21.08           & 19.60              & 37.59            \\


			                             & Random          & 86.91              & 364.46
			                             & 57.89           & 30.82              & 52.33
			                             & 20.56           & 17.00              & 35.72            \\

			\midrule
			\multirow{4}{*}{Pruned 70\%} & Taylor          & 83.25              & 274.04
			                             & 52.39           & 28.43              & 48.70
			                             & 19.11           & 17.00              & 33.12            \\

			                             & L1              & 37762.14           & 11607.13
			                             & 46.91           & 25.98              & 50.43
			                             & 20.39           & 16.40              & 32.02            \\


			                             & L2              & 394.08             & 783.72
			                             & 60.49           & 26.84              & 51.62
			                             & 20.31           & 13.20              & 34.49            \\


			                             & Random          & 4138.65            & 4074.48
			                             & 54.74           & 26.64              & 51.38
			                             & 20.99           & 14.20              & 33.59            \\
			\bottomrule
			\bottomrule
		\end{tabular}}
	\caption{Evaluierungen bis 70\% Pruning}
	\label{tab:pruning70}
\end{table}

\newpage
\subsection{Speicherverbrauch}


\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{l | c c | c c | c }
			\toprule
			\toprule
			\textbf{Pruning ratio} & \textbf{Computation Complexity} & \textbf{Ratio} & \textbf{GPU Memory Requirement} & \textbf{Ratio} & \textbf{Ratio Parameters} \\
			\midrule
			Pruned 0\%             & 77.32 GMac                      & 100\%          & 2427.31 MiB                     & 100\%          & 100\%                     \\
			Pruned 30\%            & 54.8 GMac                       & 70.87\%        & 1793.30 MiB                     & 73,86\%        & 73.06\%                   \\
			Pruned 40\%            & 51.7 GMac                       & 66.86\%        & 1709.30 MiB                     & 70,31\%        & 69.21\%                   \\
			Pruned 70\%            & 40.28 GMac                      & 52,09\%        & 1337.05 MiB                     & 55,08\%        & 55,08\%                   \\
			\bottomrule
			\bottomrule
		\end{tabular}}
	\caption{Speicheransprüche nach dem Pruning}
	\label{tab:memory}
\end{table}
