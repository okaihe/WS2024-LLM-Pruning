\section{Ergebnisse (Kai Herbst)}\label{ergebnisse}

Im folgenden Kapitel werden die Ergebnisse der Evaluierungen und Tests der
geprunten sowie teilweise anschließend trainierten Modelle vorgestellt. Der
Fokus liegt dabei insbesondere auf den ermittelten Perplexity-Werten sowie den
Ergebnissen der Tests mit dem \emph{lm-evaluation-harness}-Framework. Die
verschiedenen Pruning-Stufen und die dabei verwendeten Methoden werden einzeln
analysiert, bevor abschließend ein umfassender Gesamtüberblick über die
Ergebnisse gegeben wird.

\subsection{Evaluierung Basismodell}\label{evaluation-basemodel}

Um eine Vergleichsbasis zu schaffen, muss zunächst das Basismodell in allen
Tests evaluiert werden. Als Basismodell dient hierbei das
\emph{TinyLlama}-Modell (\emph{TinyLlama/TinyLlama-1.1B-Chat-v1.0}). Die
Darstellung der Ergebnisse orientiert sich an den vom \emph{LLM-Pruner} für
andere Modelle bereitgestellten Resultaten, um eine einheitliche
Vergleichbarkeit zu gewährleisten.

Die Spalte \emph{Average} gibt den Durchschnitt der getesteten \emph{Tasks}
wieder. Die Ergebnisse für \emph{WikiText2} und \emph{PTB} werden dabei nicht in
diese Berechnung einbezogen, da bei diesen Benchmarks ein niedrigerer Score eine
bessere Leistung des Modells widerspiegelt.

Die zusammengefassten Ergebnisse sind in der folgenden Tabelle dargestellt:

\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{l l | c c | c c c c c | r}
			\toprule
			\toprule
			\textbf{Pruning Ratio}      & \textbf{Method} & \textbf{WikiText2} &
			\textbf{PTB}                & \textbf{BoolQ}  & \textbf{HellaSwag} &
			\textbf{WinoGrande}         & \textbf{ARC-c}  & \textbf{OBQA}      &
			\textbf{Average}                                                             \\
			\midrule
			\multirow{1}{*}{Pruned 0\%} & --              & 7.97               & 20.76 &
			61.31                       & 46.15           & 60.30              &
			30.12                       & 24.20           & 39.58                        \\
			\bottomrule
			\bottomrule
		\end{tabular}}
	\caption{Evaluierung des Basismodells}
	\label{tab:pruning}
\end{table}

Wie hier zu erkennen ist, weist das Basismodell bereits einen vergleichsweise
niedrigen Score von \emph{39,58} auf. Zum Vergleich: In den Ergebnissen des
\emph{LLM-Pruners} für das Modell \emph{Llama7B} ergibt sich ein
Durchschnittswert von \emph{68,59}. Allerdings wurden in diesen Tests noch
weitere \emph{Tasks} berücksichtigt, die in der vorliegenden Analyse nicht
enthalten sind.

Da sich diese Untersuchung jedoch auf die relative Verschlechterung im Vergleich
zum Basismodell konzentriert, stellt der niedrigere Ausgangswert hier kein
Problem dar.

\newpage

\subsection{Tatsächliche Anzahl geprunter Parameter}\label{param_count}

Anhand der Modellevaluierungen, die nach dem Pruning über das Evaluierungsskript
erstellt wurden, lässt sich schnell erkennen, dass die im Befehl angegebene
Menge an zu prunenden Parametern bzw. das definierte Verhältnis nicht exakt vom
\emph{LLM-Pruner} umgesetzt wird.

Am Beispiel des \emph{30\%}-Prunings zeigt sich dies wie folgt: Bei einer
angegebenen Pruning-Ratio von \emph{30\%} wäre zu erwarten, dass nach dem
Pruning noch \emph{70\%} der ursprünglichen Parameter des Basismodells erhalten
bleiben. Tatsächlich sind es in diesem Fall jedoch \emph{73,06\%}, also
\emph{3,06\%} mehr als ursprünglich vorgesehen.

Noch deutlicher wird diese Abweichung bei einer Pruning-Ratio von \emph{70\%}.
Hier sollten theoretisch nur noch \emph{30\%} der Parameter im Modell
verbleiben, tatsächlich sind es jedoch \emph{55,08\%}, was einer Differenz von
\emph{25,08\%} entspricht.

Diese Diskrepanz muss bei der Interpretation der nachfolgenden Ergebnisse
berücksichtigt werden, da die angegebenen Verhältnisse nicht mit den
tatsächlichen übereinstimmen.

\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{c | c c | c }
			\toprule
			\toprule
			\textbf{Specified ratio} & \textbf{\#Parameters before} & \textbf{\#Parameters after} & \textbf{Actual ratio} \\
			\midrule
			30\%                     & 1261.53 Mio                  & 921.65 Mio                  & 73.06\%               \\
			40\%                     & 1261.53 Mio                  & 873.22 Mio                  & 69.21\%               \\
			70\%                     & 1261.53 Mio                  & 694.83 Mio                  & 55,08\%               \\
			\bottomrule
			\bottomrule
		\end{tabular}}
	\caption{Anzahl der vorhandenen Parameter nach dem Pruning}
	\label{tab:actualparameters}
\end{table}

\newpage

\subsection{Evaluierung der reduzierten Modelle}

\subsubsection{Evaluierung Pruning zu 30\%}\label{evaluation-30}

In Tabelle \ref{tab:pruning30} sind die Ergebnisse der geprunten Modelle sowie
die des Basismodells dargestellt. Getestet wurden – wie in Kapitel
\ref{methodik} beschrieben – die \emph{Tasks} BoolQ, HellaSwag, WinoGrande,
ARC-Challenge und OpenBookQA. Zusätzlich wurde die \emph{Perplexity} anhand der
Datensätze WikiText2 und PTB ermittelt.

\vspace{1em}
\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{l l | c c | c c c c c | r}
			\toprule
			\toprule
			\textbf{Pruning Ratio}       & \textbf{Method} & \textbf{WikiText2} &
			\textbf{PTB}                 & \textbf{BoolQ}  & \textbf{HellaSwag} &
			\textbf{WinoGrande}          & \textbf{ARC-c}  & \textbf{OBQA}      & \textbf{Average}   \\
			\midrule

			\multirow{1}{*}{Pruned 0\%}  & --              & 7.97               & 20.76
			                             & 61.31           & 46.15              & 60.30            &
			30.12                        & 24.20           & 39.58                                   \\

			\midrule

			\multirow{4}{*}{Pruned 30\%} & Taylor          & 15.19              & 43.19
			                             & 55.50           & 37.90              & 54.22
			                             & 24.66           & 23.20              & 39.10              \\

			                             & L1              & 281.63             & 4992.16
			                             & 46.54           & 28.53              & 48.46
			                             & 21.33           & 14.00              & 31.77              \\


			                             & L2              & 42.19              & 167.51
			                             & 60.89           & 35.97              & 54.30
			                             & 22.95           & 18.40              & 38.50              \\


			                             & Random          & 40.89              & 166.21
			                             & 59.63           & 33.18              & 53.99
			                             & 20.99           & 18.00              & 37.17              \\
			\midrule
			Pruned 30\% (tuned)          & Taylor          & /                  & /
			                             & 45.75           & 39.29              & 56.67
			                             & 25.26           & 22.00              & 37.79              \\
			\bottomrule
			\bottomrule
		\end{tabular}}
	\caption{Evaluierungen bis 30\% Pruning}
	\label{tab:pruning30}
\end{table}

Es ist wichtig zu beachten, dass die tatsächliche Anzahl der Parameter im
Vergleich zum Basismodell nur um \emph{26,94\%} reduziert wurde – und nicht, wie
ursprünglich erwartet, um volle \emph{30\%}. Die Tests wurden unmittelbar nach
dem Pruning durchgeführt, ohne dass ein erneutes Fine-Tuning erfolgte.

Betrachtet man ausschließlich die Ergebnisse der \emph{Tasks} und deren
Durchschnittswerte, so schneiden die \emph{Taylor}- und \emph{L2}-Methoden am
besten ab, da ihre Werte am nächsten an denen des Basismodells liegen.
Allerdings zeigt sich bei der \emph{L2}-Methode eine deutlich höhere und damit
schlechtere \emph{Perplexity} in beiden Datensätzen im Vergleich zur
\emph{Taylor}-Methode. Hervorzuheben ist dennoch, dass sie in der
\emph{BoolQ}-Task um \emph{5,39} Prozentpunkte besser abgeschnitten hat als die
\emph{Taylor}-Methode.

Die \emph{Random}-Methode weist mit ihren Resultaten Ähnlichkeiten zur
\emph{L2}-Methode auf und schneidet somit ebenfalls schlechter als die
\emph{Taylor}-Methode ab. Hier sind keine weiteren Auffälligkeiten
hervorzuheben.

Am schlechtesten hat die \emph{L1}-Methode abgeschnitten: Das daraus
resultierende Modell weist extrem schlechte \emph{Perplexity}-Werte auf, und
auch der Durchschnitt der \emph{Tasks} liegt im Vergleich zu den anderen
Methoden deutlich niedriger.

In der letzten Zeile der Tabelle sind zusätzlich die Ergebnisse des
nachtrainierten Taylor-Modells zu sehen. Leider konnten hier keine
vergleichbaren Ergebnisse wie in der Dokumentation des \emph{LLM-Pruners}
erzielt werden. Nach einem dreistündigen Post-Training ist der Durchschnittswert
von 39,85 auf 37,79 gesunken. Das Modell hat damit nach dem Post-Training
schlechtere Ergebnisse geliefert als zuvor. Lediglich in den
Evaluierungsaufgaben \emph{HellaSwag} und \emph{ARC-c} konnte eine leichte
Steigerung erzielt werden.

\newpage

\subsubsection{Evaluierung Pruning zu 40\%}

In Tabelle \ref{tab:pruning40} sind die Inhalte der Tabelle
\ref{tab:pruning30} ergänzt um die Ergebnisse der Tests zu den Modellen, die mit
der Angabe \emph{40\%} geprunt wurden zu sehen. Es wurden erneut jeweils die
vier möglichen Methoden angewendet und getestet.

\vspace{1em}
\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{l l | c c | c c c c c | r}
			\toprule
			\toprule
			\textbf{Pruning Ratio}       & \textbf{Method} & \textbf{WikiText2} &
			\textbf{PTB}                 & \textbf{BoolQ}  & \textbf{HellaSwag} &
			\textbf{WinoGrande}          & \textbf{ARC-c}  & \textbf{OBQA}      & \textbf{Average} \\
			\midrule

			\multirow{1}{*}{Pruned 0\%}  & --              & 7.97               & 20.76
			                             & 61.31           & 46.15              & 60.30
			                             & 30.12           & 24.20              & 39.58            \\

			\midrule

			\multirow{4}{*}{Pruned 30\%} & Taylor          & 15.19              & 43.19
			                             & 55.50           & 37.90              & 54.22
			                             & 24.66           & 23.20              & 39.10            \\

			                             & L1              & 281.63             & 4992.16
			                             & 46.54           & 28.53              & 48.46
			                             & 21.33           & 14.00              & 31.77            \\


			                             & L2              & 42.19              & 167.51
			                             & 60.89           & 35.97              & 54.30
			                             & 22.95           & 18.40              & 38.50            \\


			                             & Random          & 40.89              & 166.21
			                             & 59.63           & 33.18              & 53.99
			                             & 20.99           & 18.00              & 37.17            \\
			\midrule
			Pruned 30\% (tuned)          & Taylor          & /                  & /
			                             & 45.75           & 39.29              & 56.67
			                             & 25.26           & 22.00              & 37.79            \\
			\midrule

			\multirow{4}{*}{Pruned 40\%} & Taylor          & 18.43              & 53.33
			                             & 59.39           & 34.84              & 52.88
			                             & 23.55           & 18.80              & 37.89            \\

			                             & L1              & 441.35             & 14000.87
			                             & 48.99           & 28.13              & 49.96
			                             & 21.42           & 14.80              & 32.66            \\


			                             & L2              & 86.23              & 229.87
			                             & 60.83           & 34.18              & 51.62
			                             & 21.08           & 19.60              & 37.59            \\


			                             & Random          & 86.91              & 364.46
			                             & 57.89           & 30.82              & 52.33
			                             & 20.56           & 17.00              & 35.72            \\
			\bottomrule
			\bottomrule
		\end{tabular}}
	\caption{Evaluierungen bis 40\% Pruning}
	\label{tab:pruning40}
\end{table}

Auch hier zeigt sich, dass die \emph{Taylor}-Methode die vielversprechendsten
Ergebnisse erzielt. Mit einem durchschnittlichen Score von 37.89 übersteigt die
Methode bei einer angegebenen Pruning-Ratio von 40\% bzw. tatsächlichen
Pruning-Ratio von 30,79\% noch ein besseres Ergebnis als die nachtrainierte
Version des 30\%-Modells.

Ebenso erzielt die \emph{L1} erneut im Vergleich die schlechtesten Ergebnisse.
Mit einer Perplexity von ca. 14.000 erreicht diese Methode ein extrem schlechtes
Ergebnis. Deutlich schlechter in den Tests schneidet die Methode insbesondere
bei den beiden Tasks \emph{BoolQ} und \emph{HellaSwag} ab.

Die \emph{L2}-Methode erzielt wiederholt ähnliche, wenn auch leicht schlechtere,
Ergebnisse als die \emph{Taylor}-Methode. Die \emph{Random}-Methode liegt ebenso
erneut auf dem 3. Platz.

\newpage

\subsubsection{Evaluierung Pruning zu 70\%}

Zuletzt wird das Modell betrachtet, das mit einer angegebenen Pruning-Ratio von
70\% reduziert wurde (tatsächlich nur um 44,92\%). Zu sehen in Tabelle
\ref{tab:pruning70} sind die vorherigen Ergebnisse erweitert um die Resultate
der vier Methoden, mit denen das Modell reduziert wurde.

\vspace{1em}
\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{l l | c c | c c c c c | r}
			\toprule
			\toprule
			\textbf{Pruning Ratio}       & \textbf{Method} & \textbf{WikiText2} &
			\textbf{PTB}                 & \textbf{BoolQ}  & \textbf{HellaSwag} &
			\textbf{WinoGrande}          & \textbf{ARC-c}  & \textbf{OBQA}      & \textbf{Average} \\
			\midrule
			\multirow{1}{*}{Pruned 0\%}  & --              & 7.97               & 20.76
			                             & 61.31           & 46.15              & 60.30
			                             & 30.12           & 24.20              & 39.58            \\

			\midrule
			\multirow{4}{*}{Pruned 30\%} & Taylor          & 15.19              & 43.19
			                             & 55.50           & 37.90              & 54.22
			                             & 24.66           & 23.20              & 39.10            \\

			                             & L1              & 281.63             & 4992.16
			                             & 46.54           & 28.53              & 48.46
			                             & 21.33           & 14.00              & 31.77            \\

			                             & L2              & 42.19              & 167.51
			                             & 60.89           & 35.97              & 54.30
			                             & 22.95           & 18.40              & 38.50            \\

			                             & Random          & 40.89              & 166.21
			                             & 59.63           & 33.18              & 53.99
			                             & 20.99           & 18.00              & 37.17            \\

			\midrule
			Pruned 30\% (tuned)          & Taylor          & /                  & /
			                             & 45.75           & 39.29              & 56.67
			                             & 25.26           & 22.00              & 37.79            \\

			\midrule
			\multirow{4}{*}{Pruned 40\%} & Taylor          & 18.43              & 53.33
			                             & 59.39           & 34.84              & 52.88
			                             & 23.55           & 18.80              & 37.89            \\

			                             & L1              & 441.35             & 14000.87
			                             & 48.99           & 28.13              & 49.96
			                             & 21.42           & 14.80              & 32.66            \\


			                             & L2              & 86.23              & 229.87
			                             & 60.83           & 34.18              & 51.62
			                             & 21.08           & 19.60              & 37.59            \\


			                             & Random          & 86.91              & 364.46
			                             & 57.89           & 30.82              & 52.33
			                             & 20.56           & 17.00              & 35.72            \\

			\midrule
			\multirow{4}{*}{Pruned 70\%} & Taylor          & 83.25              & 274.04
			                             & 52.39           & 28.43              & 48.70
			                             & 19.11           & 17.00              & 33.12            \\

			                             & L1              & 37762.14           & 11607.13
			                             & 46.91           & 25.98              & 50.43
			                             & 20.39           & 16.40              & 32.02            \\


			                             & L2              & 394.08             & 783.72
			                             & 60.49           & 26.84              & 51.62
			                             & 20.31           & 13.20              & 34.49            \\


			                             & Random          & 4138.65            & 4074.48
			                             & 54.74           & 26.64              & 51.38
			                             & 20.99           & 14.20              & 33.59            \\
			\bottomrule
			\bottomrule
		\end{tabular}}
	\caption{Evaluierungen bis 70\% Pruning}
	\label{tab:pruning70}
\end{table}

Die \emph{Taylor}-Methode schneidet hierbei bezüglich des durchschnittlichen
Scores – abgesehen von der Perplexity – zum ersten Mal nicht am besten unter den
vier zur Verfügung stehenden Methoden ab, sondern belegt Platz drei. Unter
Berücksichtigung der Perplexity auf den beiden Testdatensätzen, die im Vergleich
deutlich besser ist, lässt sich jedoch zusammenfassend sagen, dass sie auch hier
die vielversprechendste Methode ist.

Bezüglich der fünf Tests führt hierbei die \emph{L2}-Methode, erzielt jedoch,
wie bereits erwähnt, hinsichtlich der Perplexity deutlich schlechtere Resultate.

Interessant ist jedoch, dass bei einer so hohen Pruning-Ratio wie hier angegeben
die Ergebnisse nicht wesentlich schlechter als die des Basismodells ausfallen.

\newpage
\subsection{Rechenanforderungen}

Zuletzt werden die Auswirkungen des Prunings auf die Rechenkomplexität (engl.
Computational Complexity) und die benötigten Speicheranforderungen an die GPU
(engl. GPU Memory Requirement) betrachtet. Die Ergebnisse der Evaluierungen sind
in Tabelle \ref{tab:memory} dargestellt. Zu sehen ist, dass mit der Abnahme der
tatsächlichen Parameter auch die Rechenkomplexität ungefähr proportional sinkt.
Bei einem angegebenen Pruning-Verhältnis von 30\% und tatsächlich verbleibenden
73,06\% der Parameter konnte die Rechenkomplexität um 29,13\% reduziert werden.

Gleiches gilt für die Speicheranforderungen an die GPU, die in etwa im selben
Maße abnehmen, wie die Anzahl der Parameter im Modell reduziert wird.

\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{l c | c c | c c }
			\toprule
			\toprule
			\textbf{Pruning ratio} & \textbf{Parameters left} & \textbf{Computational Complexity} & \textbf{Ratio} & \textbf{GPU Memory Requirement} & \textbf{Ratio} \\
			\midrule
			Pruned 0\%             & 100\%                    & 77.32 GMac                        & 100\%          & 2427.31 MiB                     & 100\%          \\
			Pruned 30\%            & 73.06\%                  & 54.8 GMac                         & 70.87\%        & 1793.30 MiB                     & 73,86\%        \\
			Pruned 40\%            & 69.21\%                  & 51.7 GMac                         & 66.86\%        & 1709.30 MiB                     & 70,31\%        \\
			Pruned 70\%            & 55,08\%                  & 40.28 GMac                        & 52,09\%        & 1337.05 MiB                     & 55,08\%        \\
			\bottomrule
			\bottomrule
		\end{tabular}}
	\caption{Speicheransprüche nach dem Pruning}
	\label{tab:memory}
\end{table}

Das ist insofern nicht weiter überraschend, als die Speicheranforderungen und
die benötigte Rechenleistung von der Anzahl der Parameter abhängen, von der
wiederum die Anzahl der durchzuführenden mathematischen Operationen bestimmt
wird.
